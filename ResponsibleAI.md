- Key aspects of responsible AI
  - Fairness / Bias
    -  mitigation
      - preprocessing (re-weighting)
      - Inprocessing (Adversarial debiasing)
      - Postprocessing (Decision Threshold, Rejection option classification)
      - Fairness thru unawareness
  -  Explainability / Interpretability
      -  Post-hoc - explain a given AI model
          - individual prediction explaination of input features / influentual examples / concepts / local decision rules
          - global prediction explanation - partial dependency plots / global feaure importance / global decision rules
      - build an interpretable model - logistic regression / decision trees / GAMs
      - LIME (local interpretable model - agmostic explanations) / SHAP (Shapley Additive exPlanations) shapley values
      - GradCAM (Gradient weighted class activation mapping)
  -  Robustness
      - model behaving differentialy under different setting - shift in the distribution of data
      - representative data
      - monitoring
      - adversarial training
  -  Privacy
      - private data should remain private
      - de-identification
      - anonymization
      - Re-identifiction risk, model inversion attacks
      - differential privacy
      - k-anonymity
      - federated learning 
  -  Security
      - how is sensitive data protected ?
      - effective cyber security techniques
      - adversarial attacks / adversarial training / gradient masking  
  -  Transparency
      -  model cards - how was the model built / data used etc
      -  data cards - how was the data created
  -  Accountability
- Regulations
  -  DPDP Act
      -  Digital privacy data protection ACT 2023
      -  data principal / consent manager / data protection board (DPB) / data processor / data fiduciary / significant data fiduciary
        
  -  GDPR
      -  General data protection regulation
      -  European economic area , switzerland, UK
      -  prohits processing of personal data / cannot scrap personal data
      -  DPIA - data protection impact assessments / article 35/36
      -  Data protection officer    
  -  EU AI Act
      -  https://www2.deloitte.com/nl/nl/pages/legal/articles/political-agreement-on-the-EU-AI-act.html
      -  AI Act is heavily inspired by the GDPR with similar features such as principles, user rights, transparency obligations and self-assessments
      -  fines
          - The AI Act provides for huge fines, almost two times higher than under the GDPR.
          - For the most severe violations of the prohibited applications, fines can go up to 7% of the global turnover or
          - €35 million (GDPR: 4%/€20 million), and up to 1.5% for failing to cooperate with authorities and/or to provide accurate information.
      -  exemptions
          -  The Act sets out a few exemptions from its scope, such as AI systems exclusively used for military, defence or national security purposes,
          -  or AI systems and AI models specifically developed and put into service for the sole purpose of scientific research and development.
  -  US Regulation
      -  not act as of now. Policy formulation in process.
      -  In the absence of overarching regulation in the United States, AI is currently governed by a mix of the federal government, state governments, industry itself, and the courts. 
      -  National institute of standards and technology - risk assessment in AI
      -  Artificial Intelligence Safety Institute Consortium (AISIC) - https://www.nist.gov/aisi/artificial-intelligence-safety-institute-consortium-aisic
      -  The Consortium brings together more than 200 organizations to develop science-based and empirically backed guidelines and standards for AI measurement and policy, laying the foundation for AI safety across the world.
  -  Ethical approvals
  -  Informed consent
  -  participatory design - 4 c's - consultation / contribution / collaboration / co-design
  -  Future of work 
  -  
