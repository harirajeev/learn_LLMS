![image](https://github.com/user-attachments/assets/f5b34532-1bae-48d5-a237-8013f8ab1e1d)


What We Learned from a Year of Building with LLMs - Eugene Yan, Bryan Bischof, Charles Frye, Hamel Husain, Jason Liu and Shreya Shankar
  - [Part 1 - tactical nuts and bolts of working with LLMs](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)
  - [Part 2 - long-term strategic considerations](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-ii/)
    -  [Instructor](https://github.com/jxnl/instructor) and [Outlines](https://github.com/outlines-dev/outlines) are the de facto standards for coaxing structured output from LLMs.
    -  If youâ€™re using an LLM API (e.g., Anthropic, OpenAI), use Instructor; if youâ€™re working with a self-hosted model (e.g., Hugging Face), use Outlines.
  - [Part 3](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-iii-strategy/)


Responsible AI
- [ResponsibleLLMs](https://github.com/harirajeev/learn_LLMS/blob/main/ResponsibleLLMs.md)

RAG
-  https://github.com/harirajeev/learn_LLMS/blob/main/RAG.md

LLMs can be categorised based on the number of parameters:
- ğ—¦ğ—ºğ—®ğ—¹ğ—¹: â‰¤ 1 billion parameters
- ğ— ğ—²ğ—±ğ—¶ğ˜‚ğ—º: 1 to 10 billion parameters
- ğ—Ÿğ—®ğ—¿ğ—´ğ—²: 10 to 100 billion parameters
- ğ—©ğ—²ğ—¿ğ˜† ğ—Ÿğ—®ğ—¿ğ—´ğ—²: > 100 billion parameters
