![image](https://github.com/user-attachments/assets/f5b34532-1bae-48d5-a237-8013f8ab1e1d)


What We Learned from a Year of Building with LLMs - Eugene Yan, Bryan Bischof, Charles Frye, Hamel Husain, Jason Liu and Shreya Shankar
  - [Part 1 - tactical nuts and bolts of working with LLMs](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-i/)
  - [Part 2 - long-term strategic considerations](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-ii/)
    -  [Instructor](https://github.com/jxnl/instructor) and [Outlines](https://github.com/outlines-dev/outlines) are the de facto standards for coaxing structured output from LLMs.
    -  If you’re using an LLM API (e.g., Anthropic, OpenAI), use Instructor; if you’re working with a self-hosted model (e.g., Hugging Face), use Outlines.
  - [Part 3](https://www.oreilly.com/radar/what-we-learned-from-a-year-of-building-with-llms-part-iii-strategy/)


Responsible AI
- [ResponsibleLLMs](https://github.com/harirajeev/learn_LLMS/blob/main/ResponsibleLLMs.md)

RAG
-  https://github.com/harirajeev/learn_LLMS/blob/main/RAG.md

LLMs can be categorised based on the number of parameters:
- 𝗦𝗺𝗮𝗹𝗹: ≤ 1 billion parameters
- 𝗠𝗲𝗱𝗶𝘂𝗺: 1 to 10 billion parameters
- 𝗟𝗮𝗿𝗴𝗲: 10 to 100 billion parameters
- 𝗩𝗲𝗿𝘆 𝗟𝗮𝗿𝗴𝗲: > 100 billion parameters
