From OpenAI
- 1 token ~= 4 chars in English
- 1 token ~= Â¾ words
- 100 tokens ~= 75 words
- 1,500 words ~= 2k tokens
- Since, 500 words ~= 1 A4 page
- 4k ~= 6 A4 pages of text

1. https://thegradient.pub/in-context-learning-in-context/
2. http://ai.stanford.edu/blog/understanding-incontext/
3. [LARGER LANGUAGE MODELS DO IN-CONTEXT LEARNING DIFFERENTLY](https://arxiv.org/pdf/2303.03846.pdf)
4. https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html
5. [Scaling Transformer to 1M tokens and beyond with RMT](https://arxiv.org/pdf/2304.11062.pdf) 


![image](https://github.com/harirajeev/learn_LLMS/assets/13446418/0d7a98d0-31b1-4fd6-ab05-f04fcab97182)
